{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusers.schedulers import PNDMScheduler\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from torch.onnx import export\n",
    "from pathlib import Path\n",
    "from packaging import version\n",
    "from diffusers import DiffusionPipeline\n",
    "import os\n",
    "import shutil\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Text Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = pipeline.tokenizer(\n",
    "    [\"A smile cat\"],\n",
    "    padding=\"max_length\",\n",
    "    max_length=pipeline.tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    ).input_ids.to(device=device, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 77, 768)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort = onnxruntime.InferenceSession('./onnx-models/TextEmbedding/model.onnx')\n",
    "out_t_embed = ort.run(None, {'prompt': text_input.detach().cpu().numpy()})[0]\n",
    "out_t_embed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_de = onnxruntime.InferenceSession('./onnx-models/Denoising/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_de = ort_de.run(None, {'encoder_hidden_states': out_t_embed})[0]\n",
    "out_de.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def numpy_to_pil(images):\n",
    "    \"\"\"\n",
    "    Convert a numpy image or a batch of images to a PIL image.\n",
    "    \"\"\"\n",
    "    if images.ndim == 3:\n",
    "        images = images[None, ...]\n",
    "    images = (images * 255).round().astype(\"uint8\")\n",
    "    if images.shape[-1] == 1:\n",
    "        # special case for grayscale (single channel) images\n",
    "        pil_images = [Image.fromarray(image.squeeze(), mode=\"L\") for image in images]\n",
    "    else:\n",
    "        pil_images = [Image.fromarray(image) for image in images]\n",
    "\n",
    "    return pil_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_VaeDecoder = onnxruntime.InferenceSession('./onnx-models/Decoder/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ort_VaeDecoder.run(None, {'latent_sample' : out_de.astype(np.float16)})[0]\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = numpy_to_pil(out)\n",
    "img[0].show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
