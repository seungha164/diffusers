{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from diffusers.schedulers import PNDMScheduler\n",
    "import onnx\n",
    "import onnxruntime\n",
    "from torch.onnx import export\n",
    "from pathlib import Path\n",
    "from packaging import version\n",
    "from diffusers import DiffusionPipeline\n",
    "import os\n",
    "import shutil\n",
    "from typing import List, Optional, Tuple, Union\n",
    "import numpy as np\n",
    "import inspect\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = DiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_torch_less_than_1_11 = version.parse(version.parse(torch.__version__).base_version) < version.parse(\"1.11\")\n",
    "\n",
    "def onnx_export(\n",
    "    \n",
    "    model,\n",
    "    model_args: tuple,\n",
    "    output_path: Path,\n",
    "    ordered_input_names,\n",
    "    output_names,\n",
    "    dynamic_axes,\n",
    "    opset,\n",
    "    use_external_data_format=False,\n",
    "):\n",
    "    print('ONNX export Start🚗')\n",
    "    output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    # PyTorch deprecated the `enable_onnx_checker` and `use_external_data_format` arguments in v1.11,\n",
    "    # so we check the torch version for backwards compatibility\n",
    "    if is_torch_less_than_1_11:\n",
    "        export(\n",
    "            model,\n",
    "            model_args,\n",
    "            f=output_path.as_posix(),\n",
    "            input_names=ordered_input_names,\n",
    "            output_names=output_names,\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            use_external_data_format=use_external_data_format,\n",
    "            enable_onnx_checker=True,\n",
    "            opset_version=opset,\n",
    "        )\n",
    "    else:\n",
    "        export(\n",
    "            model,\n",
    "            model_args,\n",
    "            f=output_path.as_posix(),\n",
    "            input_names=ordered_input_names,\n",
    "            output_names=output_names,\n",
    "            dynamic_axes=dynamic_axes,\n",
    "            do_constant_folding=True,\n",
    "            opset_version=opset,\n",
    "        )\n",
    "    print('ONNX export Finish🍷')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Text embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedding(nn.Module):\n",
    "    def __init__(self, tokenizer, textencoder, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text_encoder = textencoder.to(device = device)\n",
    "        self.device = device\n",
    "       \n",
    "    def forward(self, text_ids):\n",
    "        # uncond-input 준비\n",
    "        uncond_input = self.tokenizer(\n",
    "            [\"\"],\n",
    "            padding=\"max_length\",\n",
    "            max_length=pipeline.tokenizer.model_max_length,\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).input_ids\n",
    "        # 인코딩 \n",
    "        textembed               = self.text_encoder(text_ids.to(device=self.device, dtype=torch.int32)).last_hidden_state\n",
    "        negative_prompt_embeds  = self.text_encoder(uncond_input.to(device=self.device, dtype=torch.int32)).last_hidden_state\n",
    "        \n",
    "        prompt_embeds = torch.cat([negative_prompt_embeds, textembed])\n",
    "        return prompt_embeds\n",
    "        \n",
    "te = TextEmbedding(pipeline.tokenizer, pipeline.text_encoder, 'cuda')\n",
    "text_input = pipeline.tokenizer(\n",
    "    [\"A sample prompt\"],\n",
    "    padding=\"max_length\",\n",
    "    max_length=pipeline.tokenizer.model_max_length,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    "    ).input_ids.to(device=device, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export Start🚗\n",
      "ONNX export Finish🍷\n"
     ]
    }
   ],
   "source": [
    "onnx_export(\n",
    "    TextEmbedding(pipeline.tokenizer, pipeline.text_encoder, 'cpu'),\n",
    "    model_args=(\n",
    "        text_input\n",
    "    ),\n",
    "    output_path = Path('./onnx-models/TextEmbedding/model.onnx'),\n",
    "    ordered_input_names=[\"prompt\"],\n",
    "    output_names=[\"out_sample\"],  # has to be different from \"sample\" for correct tracing\n",
    "    dynamic_axes={\n",
    "        \"prompt\": {0: \"batch\", 1: \"sequence\"},\n",
    "    },\n",
    "    opset=14,\n",
    "    use_external_data_format=True,  # UNet is > 2GB, so the weights need to be split\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### VAE Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vae_decoder, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.vae_decoder = vae_decoder\n",
    "        self.vae_decoder = vae_decoder.to(device = device)\n",
    "        self.device = device\n",
    "       \n",
    "    def forward(self, latent_sample):\n",
    "        latent_sample = 1 / 0.18215 * latent_sample\n",
    "        # 통과\n",
    "        image = self.vae_decoder(latent_sample)['sample']       # [1, 3, 512, 512]\n",
    "        image = torch.clip(image / 2 + 0.5, 0, 1)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX export Start🚗\n",
      "ONNX export Finish🍷\n"
     ]
    }
   ],
   "source": [
    "vae_decoder = pipeline.vae\n",
    "vae_decoder.forward = pipeline.vae.decode\n",
    "\n",
    "onnx_export(\n",
    "    Decoder(vae_decoder, 'cpu'),\n",
    "    model_args=(\n",
    "        torch.randn(1, 4, 64, 64).to(device=device, dtype=dtype),\n",
    "    ),\n",
    "    output_path = Path('./onnx-models/Decoder/model.onnx'),\n",
    "    ordered_input_names=[\"latent_sample\"],\n",
    "    output_names=[\"out_sample\"],  # has to be different from \"sample\" for correct tracing\n",
    "    dynamic_axes={\n",
    "        \"latent_sample\": {0: \"batch\", 1: \"channels\", 2: \"height\", 3: \"width\"},\n",
    "    },\n",
    "    opset=14,\n",
    "    use_external_data_format=True,  # UNet is > 2GB, so the weights need to be split\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
